import pandas as pd
import os
import time
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from datetime import datetime

RANDOM_STATE = 42
N_ITER_RANDOM_SEARCH_RF = 20
CV_FOLDS_OPTIMIZATION = 5

def tune_random_forest(data_path):
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

    # ƒê·ªçc d·ªØ li·ªáu
    df = pd.read_csv(data_path)
    if 'NObeyesdad' not in df.columns:
        raise ValueError("C·ªôt 'NObeyesdad' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.")

    X = df.drop(columns=["NObeyesdad"])
    y = df["NObeyesdad"]

    # Chia t·∫≠p hu·∫•n luy·ªán / validation
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )

    # Ti·ªÅn x·ª≠ l√Ω
    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

    # Thi·∫øt l·∫≠p RandomizedSearchCV
    param_dist_rf = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2'],
        'class_weight': [None, 'balanced', 'balanced_subsample']
    }

    rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)

    random_search_rf = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_dist_rf,
        n_iter=N_ITER_RANDOM_SEARCH_RF,
        cv=StratifiedKFold(n_splits=CV_FOLDS_OPTIMIZATION, shuffle=True, random_state=RANDOM_STATE),
        scoring='accuracy',
        random_state=RANDOM_STATE,
        n_jobs=-1,
        verbose=1
    )

    # T·ªëi ∆∞u
    print("‚è≥ B·∫Øt ƒë·∫ßu t·ªëi ∆∞u h√≥a tham s·ªë...")
    start_time = time.time()
    X_train_processed = preprocessor.fit_transform(X_train)  # b·∫Øt bu·ªôc c·∫ßn fit ·ªü ƒë√¢y tr∆∞·ªõc ƒë·ªÉ tr√°nh l·ªói
    random_search_rf.fit(X_train_processed, y_train)
    tuning_time = time.time() - start_time
    print("‚úÖ T·ªëi ∆∞u ho√†n t·∫•t!")

    best_rf = random_search_rf.best_estimator_
    best_rf_cv_score = random_search_rf.best_score_

    # T·∫°o pipeline cu·ªëi c√πng
    rf_tuned_model = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', best_rf)
    ])
    rf_tuned_model.fit(X_train, y_train)

    y_pred_val = rf_tuned_model.predict(X_val)
    accuracy_val = accuracy_score(y_val, y_pred_val)

    # Log k·∫øt qu·∫£
    os.makedirs("logs", exist_ok=True)
    log_path = "logs/tune_random_forest_report.txt"
    with open(log_path, "a", encoding="utf-8") as f:
        f.write("="*60 + "\n")
        f.write(f"üìò B√ÅO C√ÅO T·ªêI ∆ØU H√ìA RANDOM FOREST\nüïí Th·ªùi gian: {timestamp}\n")
        f.write(f"‚è±Ô∏è T·ªïng th·ªùi gian tuning: {tuning_time:.2f} gi√¢y\n\n")

        f.write("üìä K·∫æT QU·∫¢ C√ÅC L·∫¶N TH·ª¨:\n")
        results_df = pd.DataFrame(random_search_rf.cv_results_)
        results_df = results_df.sort_values(by="rank_test_score")
        for idx, row in results_df.iterrows():
            f.write(f"- L·∫ßn {idx + 1}:\n")
            f.write(f"  üìå Tham s·ªë: {row['params']}\n")
            f.write(f"  üéØ ƒê·ªô ch√≠nh x√°c (CV): {row['mean_test_score']:.4f} ¬± {row['std_test_score']:.4f}\n")
            f.write(f"  ‚Ü™Ô∏è X·∫øp h·∫°ng: {row['rank_test_score']}\n\n")

        f.write("üèÜ T·ªêT NH·∫§T:\n")
        f.write(f"‚úîÔ∏è Tham s·ªë t·ªët nh·∫•t: {random_search_rf.best_params_}\n")
        f.write(f"üéØ ƒê·ªô ch√≠nh x√°c t·ªët nh·∫•t (CV): {best_rf_cv_score:.4f}\n\n")

        f.write("üß™ ƒê√ÅNH GI√Å TR√äN T·∫¨P VALIDATION (X_val):\n")
        f.write(f"üéØ Accuracy: {accuracy_val:.4f}\n")
        f.write(classification_report(y_val, y_pred_val))
        f.write("\n")

    # Confusion matrix
    os.makedirs("figures", exist_ok=True)
    labels_sorted = sorted(y.unique())
    cm = confusion_matrix(y_val, y_pred_val, labels=labels_sorted)

    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels_sorted, yticklabels=labels_sorted)
    plt.title("Random Forest Confusion Matrix (Optimized)")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    safe_timestamp = timestamp.replace(":", "-")
    plt.savefig(f"figures/confusion_matrix_rf_{safe_timestamp}.png", bbox_inches="tight")
    plt.close()

    # L∆∞u model
    os.makedirs("models", exist_ok=True)
    model_path = f"models/random_forest_best_{timestamp}.pkl"
    joblib.dump(rf_tuned_model, model_path)
    print(f"‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o {model_path}")
